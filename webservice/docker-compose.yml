version: '3.1'
services:
  laypa:
    image: 'loghi/docker.laypa'
    command: 'python api/gunicorn_app.py'
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    container_name: 'laypa'
    ports:
      - '5000:5000'
    environment:
      LAYPA_MAX_QUEUE_SIZE: 128
      LAYPA_MODEL_BASE_PATH: /home/rutger/src/laypa-models/
      LAYPA_OUTPUT_BASE_PATH: /tmp/output/laypa/
      # FLASK_DEBUG: 'true'
      # FLASK_APP: 'api.app.py'
      # FLASK_RUN_HOST: '0.0.0.0'
      #
      GUNICORN_RUN_HOST: '0.0.0.0:5000'
      GUNICORN_WORKERS: 1
      GUNICORN_THREADS: 1
      GUNICORN_ACCESSLOG: '-'
    volumes:
      - '/home/rutger/src/laypa-models/:/home/rutger/src/laypa-models/'
      - '/tmp/output/laypa:/tmp/output/laypa'
    networks:
      - pipeline
    shm_size: 512mb
    restart: always
  loghi-tooling:
    image: 'loghi/docker.loghi-tooling'
    command: '/src/loghi-tooling/loghiwebservice/target/appassembler/bin/LoghiWebserviceApplication server /home/rutger/src/loghi/webservice/loghi-tooling/configuration.yml'
    container_name: 'loghi-tooling'
    ports:
      - '8080:8080'
      - '8081:8081'
    environment:
      STORAGE_LOCATION: /tmp/upload
      P2PALA_CONFIG_FILE: /doesnotexist
      EXTRACT_BASELINES_MAX_THREADS: 4
      EXTRACT_BASELINES_QUEUE_LENGTH: 64
      CUT_FROM_IMAGE_MAX_THREADS: 4
      CUT_FROM_IMAGE_QUEUE_LENGTH: 64
      LOGHI_HTR_MERGE_PAGE_MAX_THREADS: 4
      LOGHI_HTR_MERGE_PAGE_QUEUE_LENGTH: 64
      RECALCULATE_READING_ORDER_NEW_MAX_THREADS: 4
      RECALCULATE_READING_ORDER_NEW_QUEUE_LENGTH: 64
      SPLIT_PAGE_TEXT_LINE_INTO_WORDS_MAX_THREADS: 4
      SPLIT_PAGE_TEXT_LINE_INTO_WORDS_QUEUE_LENGTH: 64
      DETECT_LANGUAGE_OF_PAGE_XML_MAX_THREADS: 4
      DETECT_LANGUAGE_OF_PAGE_XML_QUEUE_LENGTH: 64
    volumes: 
      - '/home/rutger/src/loghi/webservice/loghi-tooling/configuration.yml:/home/rutger/src/loghi/webservice/loghi-tooling/configuration.yml'
      - '/tmp/upload:/tmp/upload'
    networks:
      - pipeline
    shm_size: 512mb
    restart: always
  htr:
    image: 'loghi/docker.htr'
    command: '/usr/local/bin/gunicorn --workers=1 -b :5000 wsgi:app'
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    container_name: 'htr'
    ports:
      - '5001:5000'
    environment:
      FLASK_DEBUG: 'true'
      FLASK_APP: 'api.app.py'
      FLASK_RUN_HOST: '0.0.0.0'
      LOGHI_MODEL_PATH: '/home/rutger/src/loghi-htr-models/float32-generic-2023-02-15'
      LOGHI_CHARLIST_PATH: '/home/rutger/src/loghi-htr-models/float32-generic-2023-02-15/charlist.txt'
      LOGHI_BEAMWIDTH: 1
      LOGHI_BATCHSIZE: 64
      LOGHI_OUTPUT_PATH: '/tmp/output/loghi-htr2'
    volumes:
      - '/home/rutger/src/loghi-htr-models/:/home/rutger/src/loghi-htr-models/'
      - '/tmp/output/loghi-htr2:/tmp/output/loghi-htr2'
    networks:
      - pipeline
    shm_size: 512mb
    restart: always
networks:
  pipeline:
